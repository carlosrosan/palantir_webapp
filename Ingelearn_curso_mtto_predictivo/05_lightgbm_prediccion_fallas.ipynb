{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM para Predicci√≥n de Fallas en Mantenimiento Predictivo\n",
    "\n",
    "Este notebook aplica LightGBM para predecir fallas usando datos reales de la tabla `faliure_probability_base` de MySQL.\n",
    "\n",
    "Cubre:\n",
    "- Carga de datos desde MySQL\n",
    "- Preparaci√≥n y feature engineering\n",
    "- Entrenamiento de modelo LightGBM\n",
    "- Evaluaci√≥n y m√©tricas\n",
    "- Predicciones y an√°lisis de resultados\n",
    "- Guardar y cargar modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos desde MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de la base de datos\n",
    "DB_CONFIG = {\n",
    "    'host': '127.0.0.1',\n",
    "    'database': 'palantir_maintenance',\n",
    "    'user': 'root',\n",
    "    'password': 'admin',\n",
    "    'port': 3306\n",
    "}\n",
    "\n",
    "def cargar_datos_failure_base():\n",
    "    \"\"\"Cargar datos de la tabla faliure_probability_base\"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(**DB_CONFIG)\n",
    "        if connection.is_connected():\n",
    "            query = \"\"\"\n",
    "            SELECT * \n",
    "            FROM faliure_probability_base\n",
    "            ORDER BY extraction_date DESC\n",
    "            \"\"\"\n",
    "            df = pd.read_sql(query, connection)\n",
    "            connection.close()\n",
    "            print(f\"‚úÖ Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "            return df\n",
    "    except Error as e:\n",
    "        print(f\"‚ùå Error al conectar: {e}\")\n",
    "        return None\n",
    "\n",
    "# Cargar datos\n",
    "df = cargar_datos_failure_base()\n",
    "\n",
    "if df is not None and len(df) > 0:\n",
    "    print(f\"\\nColumnas disponibles: {list(df.columns)}\")\n",
    "    print(f\"\\nPrimeras filas:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nInformaci√≥n del DataFrame:\")\n",
    "    print(df.info())\n",
    "    print(f\"\\nEstad√≠sticas descriptivas:\")\n",
    "    print(df.describe())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se pudieron cargar los datos. Verifica la conexi√≥n a la base de datos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    # Verificar valores faltantes\n",
    "    print(\"Valores faltantes por columna:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Columna': missing.index,\n",
    "        'Valores Faltantes': missing.values,\n",
    "        'Porcentaje': missing_pct.values\n",
    "    })\n",
    "    missing_df = missing_df[missing_df['Valores Faltantes'] > 0].sort_values('Valores Faltantes', ascending=False)\n",
    "    \n",
    "    if len(missing_df) > 0:\n",
    "        print(missing_df)\n",
    "    else:\n",
    "        print(\"‚úÖ No hay valores faltantes\")\n",
    "    \n",
    "    # Distribuci√≥n de algunas variables clave\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    if 'failure_count_365d' in df.columns:\n",
    "        df['failure_count_365d'].fillna(0).hist(bins=20, ax=axes[0, 0])\n",
    "        axes[0, 0].set_title('Distribuci√≥n de Failure Count (365 d√≠as)')\n",
    "        axes[0, 0].set_xlabel('Failure Count')\n",
    "        axes[0, 0].set_ylabel('Frecuencia')\n",
    "    \n",
    "    if 'sensor_critical_count_30d' in df.columns:\n",
    "        df['sensor_critical_count_30d'].fillna(0).hist(bins=20, ax=axes[0, 1])\n",
    "        axes[0, 1].set_title('Distribuci√≥n de Sensor Critical Count (30 d√≠as)')\n",
    "        axes[0, 1].set_xlabel('Critical Count')\n",
    "        axes[0, 1].set_ylabel('Frecuencia')\n",
    "    \n",
    "    if 'asset_age_days' in df.columns:\n",
    "        df['asset_age_days'].fillna(0).hist(bins=20, ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Distribuci√≥n de Edad del Activo (d√≠as)')\n",
    "        axes[1, 0].set_xlabel('Edad (d√≠as)')\n",
    "        axes[1, 0].set_ylabel('Frecuencia')\n",
    "    \n",
    "    if 'task_total_365d' in df.columns:\n",
    "        df['task_total_365d'].fillna(0).hist(bins=20, ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Distribuci√≥n de Tareas Totales (365 d√≠as)')\n",
    "        axes[1, 1].set_xlabel('Total Tareas')\n",
    "        axes[1, 1].set_ylabel('Frecuencia')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creaci√≥n de Variable Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and len(df) > 0:\n",
    "    def crear_clase_falla(row):\n",
    "        \"\"\"\n",
    "        Crear variable objetivo (clase de falla) basada en:\n",
    "        - failure_count_365d: n√∫mero de fallas en √∫ltimos 365 d√≠as\n",
    "        - sensor_critical_count_30d: n√∫mero de alertas cr√≠ticas en √∫ltimos 30 d√≠as\n",
    "        - failure_unresolved_count: fallas no resueltas\n",
    "        \n",
    "        Clases:\n",
    "        0: Sin riesgo (Bajo)\n",
    "        1: Riesgo bajo (Medio)\n",
    "        2: Riesgo alto\n",
    "        3: Riesgo cr√≠tico\n",
    "        \"\"\"\n",
    "        failure_count = row.get('failure_count_365d', 0) or 0\n",
    "        sensor_critical = row.get('sensor_critical_count_30d', 0) or 0\n",
    "        unresolved = row.get('failure_unresolved_count', 0) or 0\n",
    "        \n",
    "        # L√≥gica de clasificaci√≥n\n",
    "        score = 0\n",
    "        \n",
    "        # Puntos por fallas\n",
    "        if failure_count >= 5:\n",
    "            score += 3\n",
    "        elif failure_count >= 3:\n",
    "            score += 2\n",
    "        elif failure_count >= 1:\n",
    "            score += 1\n",
    "        \n",
    "        # Puntos por sensores cr√≠ticos\n",
    "        if sensor_critical >= 10:\n",
    "            score += 3\n",
    "        elif sensor_critical >= 5:\n",
    "            score += 2\n",
    "        elif sensor_critical >= 2:\n",
    "            score += 1\n",
    "        \n",
    "        # Puntos por fallas no resueltas\n",
    "        if unresolved >= 3:\n",
    "            score += 2\n",
    "        elif unresolved >= 1:\n",
    "            score += 1\n",
    "        \n",
    "        # Clasificar seg√∫n score total\n",
    "        if score >= 6:\n",
    "            return 3  # Cr√≠tico\n",
    "        elif score >= 4:\n",
    "            return 2  # Alto\n",
    "        elif score >= 2:\n",
    "            return 1  # Medio\n",
    "        else:\n",
    "            return 0  # Bajo\n",
    "    \n",
    "    # Aplicar funci√≥n\n",
    "    df['clase_falla'] = df.apply(crear_clase_falla, axis=1)\n",
    "    \n",
    "    # Ver distribuci√≥n de clases\n",
    "    print(\"Distribuci√≥n de clases de falla:\")\n",
    "    clase_dist = df['clase_falla'].value_counts().sort_index()\n",
    "    clase_labels = ['Bajo', 'Medio', 'Alto', 'Cr√≠tico']\n",
    "    \n",
    "    for idx, count in clase_dist.items():\n",
    "        label = clase_labels[idx] if idx < len(clase_labels) else f'Clase {idx}'\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {label}: {count} ({pct:.2f}%)\")\n",
    "    \n",
    "    # Visualizar distribuci√≥n\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    clase_dist.plot(kind='bar', color=['green', 'yellow', 'orange', 'red'])\n",
    "    plt.title('Distribuci√≥n de Clases de Falla')\n",
    "    plt.xlabel('Clase de Falla')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.xticks(range(len(clase_dist)), [clase_labels[i] if i < len(clase_labels) else f'Clase {i}' for i in clase_dist.index], rotation=0)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Variable objetivo creada: {df['clase_falla'].nunique()} clases √∫nicas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selecci√≥n y Preparaci√≥n de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'clase_falla' in df.columns:\n",
    "    # Seleccionar caracter√≠sticas relevantes\n",
    "    feature_columns = [\n",
    "        # Informaci√≥n del activo\n",
    "        'asset_age_days',\n",
    "        \n",
    "        # Caracter√≠sticas de sensores (30 d√≠as)\n",
    "        'sensor_total_readings_30d',\n",
    "        'sensor_warning_count_30d',\n",
    "        'sensor_critical_count_30d',\n",
    "        'sensor_avg_normal_value',\n",
    "        'sensor_avg_warning_value',\n",
    "        'sensor_avg_critical_value',\n",
    "        'sensor_max_value',\n",
    "        'sensor_min_value',\n",
    "        'sensor_std_value',\n",
    "        \n",
    "        # Caracter√≠sticas de fallas (365 d√≠as)\n",
    "        'failure_count_365d',\n",
    "        'failure_critical_count',\n",
    "        'failure_high_count',\n",
    "        'failure_medium_count',\n",
    "        'failure_low_count',\n",
    "        'failure_avg_downtime',\n",
    "        'failure_total_downtime',\n",
    "        'failure_unresolved_count',\n",
    "        'days_since_last_failure',\n",
    "        \n",
    "        # Caracter√≠sticas de tareas de mantenimiento (365 d√≠as)\n",
    "        'task_total_365d',\n",
    "        'task_completed_count',\n",
    "        'task_in_progress_count',\n",
    "        'task_pending_count',\n",
    "        'task_avg_estimated_hours',\n",
    "        'task_avg_actual_hours',\n",
    "        'task_total_hours',\n",
    "        'days_since_last_task',\n",
    "        \n",
    "        # Caracter√≠sticas de √≥rdenes de mantenimiento (365 d√≠as)\n",
    "        'order_total_365d',\n",
    "        'order_preventive_count',\n",
    "        'order_corrective_count',\n",
    "        'order_emergency_count',\n",
    "        'order_completed_count',\n",
    "        'order_avg_estimated_cost',\n",
    "        'order_avg_actual_cost',\n",
    "        'order_total_actual_cost',\n",
    "        'days_since_last_order'\n",
    "    ]\n",
    "    \n",
    "    # Filtrar columnas que existen en el DataFrame\n",
    "    available_features = [col for col in feature_columns if col in df.columns]\n",
    "    \n",
    "    print(f\"Caracter√≠sticas seleccionadas: {len(available_features)}\")\n",
    "    print(f\"\\nCaracter√≠sticas: {available_features}\")\n",
    "    \n",
    "    # Preparar datos\n",
    "    X = df[available_features].copy()\n",
    "    y = df['clase_falla'].copy()\n",
    "    \n",
    "    # Manejar valores faltantes\n",
    "    print(f\"\\nValores faltantes antes de limpieza: {X.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Llenar valores faltantes con 0 (asumiendo que NaN significa \"sin datos\")\n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    # Reemplazar infinitos con 0\n",
    "    X = X.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    print(f\"Valores faltantes despu√©s de limpieza: {X.isnull().sum().sum()}\")\n",
    "    print(f\"\\nForma de X: {X.shape}\")\n",
    "    print(f\"Forma de y: {y.shape}\")\n",
    "    print(f\"\\nTipos de datos:\")\n",
    "    print(X.dtypes.value_counts())\n",
    "    \n",
    "    # Verificar que tenemos suficientes datos\n",
    "    if len(X) < 50:\n",
    "        print(\"‚ö†Ô∏è ADVERTENCIA: Muy pocos datos para entrenar un modelo robusto\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Datos suficientes para entrenamiento: {len(X)} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Divisi√≥n de Datos en Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X' in locals() and 'y' in locals():\n",
    "    # Dividir datos (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=y  # Mantener proporci√≥n de clases\n",
    "    )\n",
    "    \n",
    "    print(f\"Datos de entrenamiento: {X_train.shape}\")\n",
    "    print(f\"Datos de prueba: {X_test.shape}\")\n",
    "    \n",
    "    print(f\"\\nDistribuci√≥n de clases en entrenamiento:\")\n",
    "    print(y_train.value_counts().sort_index())\n",
    "    \n",
    "    print(f\"\\nDistribuci√≥n de clases en prueba:\")\n",
    "    print(y_test.value_counts().sort_index())\n",
    "    \n",
    "    # Verificar balanceo de clases\n",
    "    train_dist = y_train.value_counts().sort_index() / len(y_train)\n",
    "    test_dist = y_test.value_counts().sort_index() / len(y_test)\n",
    "    \n",
    "    print(f\"\\nProporciones en entrenamiento:\")\n",
    "    for idx, pct in train_dist.items():\n",
    "        label = clase_labels[idx] if idx < len(clase_labels) else f'Clase {idx}'\n",
    "        print(f\"  {label}: {pct:.2%}\")\n",
    "    \n",
    "    print(f\"\\nProporciones en prueba:\")\n",
    "    for idx, pct in test_dist.items():\n",
    "        label = clase_labels[idx] if idx < len(clase_labels) else f'Clase {idx}'\n",
    "        print(f\"  {label}: {pct:.2%}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entrenamiento del Modelo LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train' in locals() and 'y_train' in locals():\n",
    "    # Configurar par√°metros de LightGBM\n",
    "    lgbm_params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': len(y_train.unique()),\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'min_child_samples': 20,\n",
    "        'lambda_l1': 0.1,\n",
    "        'lambda_l2': 0.1,\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    print(\"Par√°metros del modelo LightGBM:\")\n",
    "    for key, value in lgbm_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Crear y entrenar modelo\n",
    "    print(\"\\nüöÄ Entrenando modelo LightGBM...\")\n",
    "    \n",
    "    lgbm_model = LGBMClassifier(**lgbm_params)\n",
    "    \n",
    "    # Entrenar con validaci√≥n temprana\n",
    "    lgbm_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        eval_names=['train', 'valid'],\n",
    "        callbacks=[\n",
    "            lgbm_model.early_stopping(stopping_rounds=20, verbose=True),\n",
    "            lgbm_model.log_evaluation(period=10)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Modelo entrenado correctamente\")\n",
    "    \n",
    "    # Mostrar mejor iteraci√≥n\n",
    "    if hasattr(lgbm_model, 'best_iteration_'):\n",
    "        print(f\"Mejor iteraci√≥n: {lgbm_model.best_iteration_}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos de entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predicciones y Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lgbm_model' in locals() and 'X_test' in locals():\n",
    "    # Hacer predicciones\n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "    y_pred_proba = lgbm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(\"=== M√âTRICAS DEL MODELO ===\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
    "    print(classification_report(y_test, y_pred, target_names=clase_labels))\n",
    "    \n",
    "    # Matriz de confusi√≥n\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=clase_labels, yticklabels=clase_labels)\n",
    "    plt.title('Matriz de Confusi√≥n - LightGBM')\n",
    "    plt.ylabel('Verdadero')\n",
    "    plt.xlabel('Predicho')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay modelo entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Importancia de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lgbm_model' in locals() and 'X_train' in locals():\n",
    "    # Obtener importancia de caracter√≠sticas\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': lgbm_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 15 caracter√≠sticas m√°s importantes:\")\n",
    "    print(feature_importance.head(15))\n",
    "    \n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "    plt.title('Top 15 Caracter√≠sticas M√°s Importantes - LightGBM')\n",
    "    plt.xlabel('Importancia')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # An√°lisis de caracter√≠sticas m√°s importantes\n",
    "    print(\"\\n=== AN√ÅLISIS DE CARACTER√çSTICAS ===\")\n",
    "    top_5 = feature_importance.head(5)\n",
    "    print(\"\\nLas 5 caracter√≠sticas m√°s importantes son:\")\n",
    "    for idx, row in top_5.iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. An√°lisis de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'y_pred' in locals() and 'y_test' in locals():\n",
    "    # Crear DataFrame con predicciones y valores reales\n",
    "    resultados_df = pd.DataFrame({\n",
    "        'Real': y_test.values,\n",
    "        'Predicho': y_pred,\n",
    "        'Correcto': (y_test.values == y_pred)\n",
    "    })\n",
    "    \n",
    "    # Agregar probabilidades\n",
    "    if 'y_pred_proba' in locals():\n",
    "        for i in range(y_pred_proba.shape[1]):\n",
    "            resultados_df[f'Prob_Clase_{i}'] = y_pred_proba[:, i]\n",
    "    \n",
    "    # An√°lisis por clase\n",
    "    print(\"=== AN√ÅLISIS DE PREDICCIONES POR CLASE ===\")\n",
    "    for clase in sorted(y_test.unique()):\n",
    "        clase_nombre = clase_labels[clase] if clase < len(clase_labels) else f'Clase {clase}'\n",
    "        mask = resultados_df['Real'] == clase\n",
    "        total = mask.sum()\n",
    "        correctos = resultados_df[mask]['Correcto'].sum()\n",
    "        accuracy_clase = correctos / total if total > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{clase_nombre}:\")\n",
    "        print(f\"  Total muestras: {total}\")\n",
    "        print(f\"  Predicciones correctas: {correctos}\")\n",
    "        print(f\"  Accuracy: {accuracy_clase:.2%}\")\n",
    "    \n",
    "    # Visualizar distribuci√≥n de probabilidades\n",
    "    if 'y_pred_proba' in locals():\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        for i, clase in enumerate(sorted(y_test.unique())):\n",
    "            if i < 4:\n",
    "                ax = axes[i // 2, i % 2]\n",
    "                clase_nombre = clase_labels[clase] if clase < len(clase_labels) else f'Clase {clase}'\n",
    "                \n",
    "                mask = resultados_df['Real'] == clase\n",
    "                ax.hist(resultados_df[mask][f'Prob_Clase_{clase}'], bins=20, alpha=0.7, label='Correcto')\n",
    "                \n",
    "                mask_incorrecto = mask & ~resultados_df['Correcto']\n",
    "                if mask_incorrecto.sum() > 0:\n",
    "                    ax.hist(resultados_df[mask_incorrecto][f'Prob_Clase_{clase}'], bins=20, alpha=0.7, label='Incorrecto')\n",
    "                \n",
    "                ax.set_title(f'Distribuci√≥n de Probabilidades - {clase_nombre}')\n",
    "                ax.set_xlabel('Probabilidad')\n",
    "                ax.set_ylabel('Frecuencia')\n",
    "                ax.legend()\n",
    "                ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\nPrimeras 10 predicciones:\")\n",
    "    print(resultados_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Guardar y Cargar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lgbm_model' in locals():\n",
    "    # Guardar modelo\n",
    "    modelo_path = 'lightgbm_failure_prediction_model.pkl'\n",
    "    joblib.dump(lgbm_model, modelo_path)\n",
    "    print(f\"‚úÖ Modelo guardado en: {modelo_path}\")\n",
    "    \n",
    "    # Guardar informaci√≥n de caracter√≠sticas\n",
    "    feature_info = {\n",
    "        'feature_names': list(X_train.columns),\n",
    "        'num_classes': len(y_train.unique()),\n",
    "        'class_labels': clase_labels\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open('model_feature_info.json', 'w') as f:\n",
    "        json.dump(feature_info, f, indent=2)\n",
    "    \n",
    "    print(\"‚úÖ Informaci√≥n de caracter√≠sticas guardada en: model_feature_info.json\")\n",
    "    \n",
    "    # Ejemplo de c√≥mo cargar el modelo\n",
    "    print(\"\\n=== EJEMPLO DE CARGA DEL MODELO ===\")\n",
    "    print(\"# Para cargar el modelo en el futuro:\")\n",
    "    print(\"# loaded_model = joblib.load('lightgbm_failure_prediction_model.pkl')\")\n",
    "    print(\"# predictions = loaded_model.predict(new_data)\")\n",
    "    \n",
    "    # Verificar carga\n",
    "    loaded_model = joblib.load(modelo_path)\n",
    "    test_pred = loaded_model.predict(X_test.head(5))\n",
    "    print(f\"\\n‚úÖ Modelo cargado correctamente. Predicci√≥n de prueba: {test_pred}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay modelo para guardar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Predicci√≥n en Nuevos Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para hacer predicciones en nuevos datos\n",
    "def predecir_fallas(nuevos_datos, modelo, feature_names):\n",
    "    \"\"\"\n",
    "    Hacer predicciones de fallas en nuevos datos\n",
    "    \n",
    "    Par√°metros:\n",
    "    - nuevos_datos: DataFrame con las caracter√≠sticas\n",
    "    - modelo: Modelo LightGBM entrenado\n",
    "    - feature_names: Lista de nombres de caracter√≠sticas esperadas\n",
    "    \n",
    "    Retorna:\n",
    "    - predicciones: Array con las clases predichas\n",
    "    - probabilidades: Array con las probabilidades por clase\n",
    "    \"\"\"\n",
    "    # Asegurar que tenemos las columnas correctas\n",
    "    datos_preparados = nuevos_datos[feature_names].copy()\n",
    "    \n",
    "    # Llenar valores faltantes\n",
    "    datos_preparados = datos_preparados.fillna(0)\n",
    "    datos_preparados = datos_preparados.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    predicciones = modelo.predict(datos_preparados)\n",
    "    probabilidades = modelo.predict_proba(datos_preparados)\n",
    "    \n",
    "    return predicciones, probabilidades\n",
    "\n",
    "# Ejemplo de uso\n",
    "if 'lgbm_model' in locals() and 'X_test' in locals():\n",
    "    print(\"=== EJEMPLO DE PREDICCI√ìN EN NUEVOS DATOS ===\")\n",
    "    \n",
    "    # Usar algunas muestras de test como ejemplo\n",
    "    ejemplo_datos = X_test.head(3)\n",
    "    \n",
    "    pred_ejemplo, prob_ejemplo = predecir_fallas(\n",
    "        ejemplo_datos, \n",
    "        lgbm_model, \n",
    "        list(X_train.columns)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nPredicciones: {pred_ejemplo}\")\n",
    "    print(f\"\\nProbabilidades:\")\n",
    "    for i, (pred, prob) in enumerate(zip(pred_ejemplo, prob_ejemplo)):\n",
    "        clase_nombre = clase_labels[pred] if pred < len(clase_labels) else f'Clase {pred}'\n",
    "        print(f\"\\nMuestra {i+1}:\")\n",
    "        print(f\"  Clase predicha: {clase_nombre} ({pred})\")\n",
    "        print(f\"  Probabilidades:\")\n",
    "        for j, p in enumerate(prob):\n",
    "            clase_p = clase_labels[j] if j < len(clase_labels) else f'Clase {j}'\n",
    "            print(f\"    {clase_p}: {p:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay modelo disponible para hacer predicciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este notebook hemos aprendido:\n",
    "1. ‚úÖ Carga de datos desde MySQL (tabla `faliure_probability_base`)\n",
    "2. ‚úÖ An√°lisis exploratorio de datos\n",
    "3. ‚úÖ Creaci√≥n de variable objetivo (clases de falla)\n",
    "4. ‚úÖ Preparaci√≥n y selecci√≥n de caracter√≠sticas\n",
    "5. ‚úÖ Entrenamiento de modelo LightGBM\n",
    "6. ‚úÖ Evaluaci√≥n con m√∫ltiples m√©tricas\n",
    "7. ‚úÖ An√°lisis de importancia de caracter√≠sticas\n",
    "8. ‚úÖ An√°lisis detallado de predicciones\n",
    "9. ‚úÖ Guardar y cargar modelos\n",
    "10. ‚úÖ Funci√≥n para predecir en nuevos datos\n",
    "\n",
    "**El modelo est√° listo para ser usado en producci√≥n para predecir fallas en activos de mantenimiento.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
